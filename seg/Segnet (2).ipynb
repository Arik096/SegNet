{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,floatX=float32,optimizer=fast_compile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5cf352c2bff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1337\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import keras.layers.containers as containers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "import keras.models as models\n",
    "import keras.layers.containers as containers\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape, AutoEncoder, Merge, Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import ActivityRegularizer\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = './CamVid/'\n",
    "data_shape = 360*480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "def normalized(rgb):\n",
    "    #return rgb/255.0\n",
    "    norm=np.zeros((rgb.shape[0], rgb.shape[1], 3),np.float32)\n",
    "\n",
    "    b=rgb[:,:,0]\n",
    "    g=rgb[:,:,1]\n",
    "    r=rgb[:,:,2]\n",
    "\n",
    "    norm[:,:,0]=cv2.equalizeHist(b)\n",
    "    norm[:,:,1]=cv2.equalizeHist(g)\n",
    "    norm[:,:,2]=cv2.equalizeHist(r)\n",
    "\n",
    "    return norm\n",
    "\n",
    "def binarylab(labels):\n",
    "    x = np.zeros([360,480,12])    \n",
    "    for i in range(360):\n",
    "        for j in range(480):\n",
    "            x[i,j,labels[i][j]]=1\n",
    "    return x\n",
    "\n",
    "def prep_data():\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    import os\n",
    "    with open(path+'train.txt') as f:\n",
    "        txt = f.readlines()\n",
    "        txt = [line.split(' ') for line in txt]\n",
    "    for i in range(len(txt)):\n",
    "        ## these paths are very specific to my machine\n",
    "        train_data.append(np.rollaxis(normalized(cv2.imread(os.getcwd() + txt[i][0][7:])),2))\n",
    "        train_label.append(binarylab(cv2.imread(os.getcwd() + txt[i][1][7:][:-1])[:,:,0]))\n",
    "        print('.',end='')\n",
    "    return np.array(train_data), np.array(train_label)\n",
    "\n",
    "train_data, train_label = prep_data()\n",
    "train_label = np.reshape(train_label,(367,data_shape,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class weigths\n",
    "class_weighting= [0.2595, 0.1826, 4.5640, 0.1417, 0.9051, 0.3826, 9.6446, 1.8418, 6.6823, 6.2478, 3.0, 7.3614]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnPooling2D(Layer):\n",
    "    \"\"\"A 2D Repeat layer\"\"\"\n",
    "    def __init__(self, poolsize=(2, 2)):\n",
    "        super(UnPooling2D, self).__init__()\n",
    "        self.input = T.tensor4()\n",
    "        self.poolsize = poolsize\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        input_shape = self.input_shape\n",
    "        return (input_shape[0], input_shape[1],\n",
    "                self.poolsize[0] * input_shape[2],\n",
    "                self.poolsize[1] * input_shape[3])\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        s1 = self.poolsize[0]\n",
    "        s2 = self.poolsize[1]\n",
    "        output = X.repeat(s1, axis=2).repeat(s2, axis=3)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\":self.__class__.__name__,\n",
    "            \"poolsize\":self.poolsize}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoding_layers():\n",
    "    kernel = 3\n",
    "    filter_size = 64\n",
    "    pad = 1\n",
    "    pool_size = 2\n",
    "    return [\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(filter_size, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(128, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(256, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(512, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "    ]\n",
    "\n",
    "def create_decoding_layers():\n",
    "    kernel = 3\n",
    "    filter_size = 64\n",
    "    pad = 1\n",
    "    pool_size = 2\n",
    "    return[\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(512, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        UnPooling2D(poolsize=(pool_size,pool_size)),\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(256, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        UnPooling2D(poolsize=(pool_size,pool_size)),\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(128, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        UnPooling2D(poolsize=(pool_size,pool_size)),\n",
    "        ZeroPadding2D(padding=(pad,pad)),\n",
    "        Convolution2D(filter_size, kernel, kernel, border_mode='valid'),\n",
    "        BatchNormalization(),\n",
    "    ]\n",
    "\n",
    "autoencoder = models.Sequential()\n",
    "# Add a noise layer to get a denoising autoencoder. This helps avoid overfitting\n",
    "autoencoder.add(Layer(input_shape=(3, 360, 480)))\n",
    "\n",
    "#autoencoder.add(GaussianNoise(sigma=0.3))\n",
    "autoencoder.encoding_layers = create_encoding_layers()\n",
    "autoencoder.decoding_layers = create_decoding_layers()\n",
    "for l in autoencoder.encoding_layers:\n",
    "    autoencoder.add(l)\n",
    "for l in autoencoder.decoding_layers:\n",
    "    autoencoder.add(l)\n",
    "\n",
    "autoencoder.add(Convolution2D(12, 1, 1, border_mode='valid',))\n",
    "autoencoder.add(Reshape((12,data_shape)))\n",
    "autoencoder.add(Permute((2, 1)))\n",
    "autoencoder.add(Activation('softmax'))\n",
    "#from keras.optimizers import SGD\n",
    "#optimizer = SGD(lr=0.01, momentum=0.8, decay=0., nesterov=False)\n",
    "autoencoder.compile(loss=\"categorical_crossentropy\", optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 5\n",
    "batch_size = 10\n",
    "\n",
    "history = autoencoder.fit(train_data, train_label, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    show_accuracy=True, verbose=1, class_weight=class_weighting )#, validation_data=(X_test, X_test))\n",
    "autoencoder.save_weights('model_weight_ep100.hdf5')\n",
    "#score = autoencoder.evaluate(X_test, X_test, show_accuracy=True, verbose=0)\n",
    "#print('Test score:', score[0])\n",
    "#print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "At the end of 100 epochs training acc was about 0.91\n",
    "\n",
    "#### Epoch 100/100\n",
    "\n",
    "367/367 [==============================] - 890s - loss: 0.2942 - acc: 0.9100   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
